{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "0sWs6G3LQAYp"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnnaGass/DSA-SleepHealthData/blob/main/01_DataPreparation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title # Select the subject to be used { display-mode: \"both\" }\n",
        "subject = '020'"
      ],
      "metadata": {
        "id": "oTpYmKk4PmQW"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install python libraries and load packages"
      ],
      "metadata": {
        "id": "0sWs6G3LQAYp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Install needed libraries { display-mode: \"both\" }\n",
        "!pip install pyedflib\n",
        "!pip install pandas\n",
        "\n",
        "!pip install pandas scikit-learn"
      ],
      "metadata": {
        "id": "8pVvImhjEttu",
        "outputId": "03bb6f58-6f36-41c9-f9e0-155c40f49ffd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyedflib in /usr/local/lib/python3.10/dist-packages (0.1.37)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from pyedflib) (1.25.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.25.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Import libraries { display-mode: \"both\" }\n",
        "import subprocess\n",
        "import pyedflib\n",
        "import csv\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "from datetime import timedelta\n",
        "from datetime import datetime"
      ],
      "metadata": {
        "id": "Frrc2f2ADTB_"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Define constants { display-mode: \"both\" }\n",
        "base_url = \"https://physionet.org/files/ucddb/1.0.0/ucddb\" + subject\n",
        "orig_data = \"/content/physionet.org/files/ucddb/1.0.0/ucddb\" + subject\n",
        "\n",
        "output_directory = \"results/subject\" + subject + \"/\"\n",
        "data_prep_dir = output_directory + \"data_preparation/\"\n",
        "\n",
        "base_data = output_directory + \"base_data\" + subject + \".csv\""
      ],
      "metadata": {
        "id": "0N16aWxz3aIq"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Create output directory for subject { display-mode: \"both\" }\n",
        "\n",
        "# Create folders if not exists\n",
        "if not os.path.exists(output_directory):\n",
        "  os.makedirs(output_directory)\n",
        "\n",
        "if not os.path.exists(data_prep_dir):\n",
        "  os.makedirs(data_prep_dir)"
      ],
      "metadata": {
        "id": "rMjsnUo_2hcB"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import data"
      ],
      "metadata": {
        "id": "g5QG_0EuxMg-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Import the data from physionet { display-mode: \"both\" }\n",
        "\n",
        "base_command = \"wget -r -N -c -np \"\n",
        "\n",
        "rec_path = base_url + \".rec\"\n",
        "sleep_annotation_path = base_url + \"_stage.txt\"\n",
        "apnea_annotation_path = base_url + \"_respevt.txt\"\n",
        "\n",
        "command = base_command + rec_path\n",
        "result = subprocess.run(command, shell=True, capture_output=True, text=True)\n",
        "\n",
        "command = base_command + sleep_annotation_path\n",
        "result = subprocess.run(command, shell=True, capture_output=True, text=True)\n",
        "\n",
        "command = base_command + apnea_annotation_path\n",
        "result = subprocess.run(command, shell=True, capture_output=True, text=True)"
      ],
      "metadata": {
        "id": "--je-QuzL2Fk"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare the data"
      ],
      "metadata": {
        "id": "wBCktvBeQPfL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "i8rzXtTYEX-V",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Extract signals from .rec file\n",
        "\n",
        "# open the input file\n",
        "rec_file_path = orig_data + \".rec\"\n",
        "f = pyedflib.EdfReader(rec_file_path)\n",
        "\n",
        "# Specify the output file name\n",
        "signals_csv = data_prep_dir + \"01_orig_signals.csv\"\n",
        "\n",
        "# Specify which signals to use\n",
        "spo2_index = 6      # taken from the headers\n",
        "pulse_index = 13    # taken from the headers\n",
        "\n",
        "# Initialize an empty list to store your values\n",
        "data = []\n",
        "\n",
        "# file properties\n",
        "start_time = f.getStartdatetime()\n",
        "file_duration = f.getFileDuration()\n",
        "signal_labels = f.getSignalLabels()\n",
        "\n",
        "# SpO2 information\n",
        "spo2_header = f.getSignalHeader(spo2_index)\n",
        "spo2_signals = f.readSignal(spo2_index)\n",
        "\n",
        "# Pulse information\n",
        "pulse_header = f.getSignalHeader(pulse_index)\n",
        "pulse_signals = f.readSignal(pulse_index)\n",
        "\n",
        "# Calculate frequency\n",
        "time_between_meassurements = file_duration / len(pulse_signals)\n",
        "\n",
        "# Iterate and add the increment to the datetime on each iteration\n",
        "for i in range(len(pulse_signals)):\n",
        "    date_str = start_time.strftime('%Y-%m-%d')\n",
        "    if start_time.microsecond != 0:\n",
        "       time_str = start_time.strftime('%H:%M:%S.%f')\n",
        "    else:\n",
        "       time_str = start_time.strftime('%H:%M:%S')\n",
        "    data.append([date_str, time_str, spo2_signals[i], pulse_signals[i]])\n",
        "    start_time += timedelta(seconds=time_between_meassurements)\n",
        "\n",
        "# Write the data to a CSV file\n",
        "with open(signals_csv, 'w', newline='') as file:\n",
        "    # Create a CSV writer object for the output file\n",
        "    writer = csv.writer(file)\n",
        "    # Write the header\n",
        "    writer.writerow(['Date', 'Time', 'SpO2', 'Pulse'])\n",
        "    writer.writerows(data)\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Extract data from respevt.txt file\n",
        "\n",
        "# Specify the input file name\n",
        "annotations_path = orig_data + \"_respevt.txt\"\n",
        "\n",
        "# Specify the output file name\n",
        "output_csv_annotations = data_prep_dir + \"02_apnea_annotations.csv\"\n",
        "\n",
        "# Open the input file\n",
        "with open(annotations_path, 'r') as infile:\n",
        "    # Skip the first two lines (header)\n",
        "    next(infile)\n",
        "    next(infile)\n",
        "    next(infile)\n",
        "\n",
        "    # Open a CSV file for writing with more parameters\n",
        "    with open(output_csv_annotations, 'w', newline='') as outfile_extra:\n",
        "        # Create a CSV writer object for the output file\n",
        "        writer = csv.writer(outfile_extra)\n",
        "\n",
        "        # Write the header\n",
        "        writer.writerow(['Time', 'Apnea'])\n",
        "\n",
        "        # Process each line in the input file\n",
        "        for line in infile:\n",
        "            # Split the line into columns\n",
        "            columns = line.split()\n",
        "\n",
        "            # Check if the line has enough columns\n",
        "            if len(columns) >= 5:\n",
        "\n",
        "                # Extract the required columns\n",
        "                time_str = columns[0]\n",
        "                event_type = columns[1]\n",
        "                duration_str = columns[2] if columns[2] != \"EVENT\" else columns[4]\n",
        "\n",
        "\n",
        "                # Parse duration into seconds\n",
        "                duration_seconds = int(duration_str)\n",
        "\n",
        "                # Parse time string into datetime object\n",
        "                time = datetime.strptime(time_str, '%H:%M:%S')\n",
        "\n",
        "                # Iterate over the duration and add one second to the time in each iteration\n",
        "                for _ in range(duration_seconds):\n",
        "\n",
        "                    # Write the time, event type, and duration to the CSV file\n",
        "                    writer.writerow([time.strftime('%H:%M:%S'), event_type])\n",
        "\n",
        "                    # Add one second to the time\n",
        "                    time += timedelta(seconds=1)"
      ],
      "metadata": {
        "id": "JRRjvhibEvyF",
        "cellView": "form"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Extract data from stage.txt file\n",
        "\n",
        "# Specify the input file name\n",
        "input_stage = orig_data + \"_stage.txt\"\n",
        "\n",
        "# Specify the output file name\n",
        "output_csv_stage = data_prep_dir + \"03_sleep_stages.csv\"\n",
        "\n",
        "# Open the input text file in read mode and the output CSV file in write mode\n",
        "with open(input_stage, 'r') as infile:\n",
        "  with open(output_csv_stage, 'w', newline='') as outfile_stage:\n",
        "        # Create a CSV writer object for the output file\n",
        "        writer = csv.writer(outfile_stage)\n",
        "\n",
        "        # Write the header\n",
        "        writer.writerow(['Sleep Stage'])\n",
        "\n",
        "        # Process each line in the input file\n",
        "        for line in infile:\n",
        "            # Remove leading and trailing whitespace and split the line into columns\n",
        "            line = line.strip()\n",
        "            # Write the sleep stage value to the CSV file\n",
        "            writer.writerow([line])"
      ],
      "metadata": {
        "id": "hCA8sxBMAzC6",
        "cellView": "form"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Sort the data in the orig_signals.csv and merge it with sleep_stages.csv and apnoe_annotations.csv\n",
        "\n",
        "merged_csv = data_prep_dir + \"04_merged.csv\"\n",
        "\n",
        "# Load data from the _signals.csv file\n",
        "df_signals = pd.read_csv(signals_csv)\n",
        "\n",
        "# Sort the data to keep only the rows where the time values have seconds only\n",
        "df_signals = df_signals[df_signals['Time'].str.contains(r'^\\d{2}:\\d{2}:\\d{2}$')]\n",
        "df_signals_withoutmiliseconds = df_signals.copy()\n",
        "\n",
        "# Load data from the apnea_annotations.csv file and merge it with the filtered signal data using the 'Time' column\n",
        "df_apnea_anno = pd.read_csv(output_csv_annotations)\n",
        "df_merged_anno = pd.merge(df_signals_withoutmiliseconds, df_apnea_anno, on='Time', how='left')\n",
        "\n",
        "# =================================================================================================\n",
        "\n",
        "# Load data from the sleep_stages.csv file\n",
        "df_apnea_stage = pd.read_csv(output_csv_stage, dtype=int)\n",
        "\n",
        "# Initialize an empty list to store combined data\n",
        "combined_data = []\n",
        "\n",
        "for i in range(len(df_signals_withoutmiliseconds)):\n",
        "    # Calculate the index for the data from df_apnea_stage based on the 30-second intervals\n",
        "    apnea_index = i // 30\n",
        "\n",
        "    # Ensure the index does not exceed the number of rows in df_apnea_stage\n",
        "    apnea_index = min(apnea_index, len(df_apnea_stage) - 1)\n",
        "\n",
        "    # Append the corresponding entry from df_apnea_stage to the combined data list\n",
        "    combined_data.append(df_apnea_stage.iloc[apnea_index].tolist())\n",
        "\n",
        "# Convert the combined data list into a DataFrame\n",
        "df_combined_stage = pd.DataFrame(combined_data, columns=df_apnea_stage.columns)\n",
        "\n",
        "# Merge the combined data with the merged signal and annotation data\n",
        "df_merged_stage = pd.concat([df_merged_anno, df_combined_stage], axis=1)\n",
        "\n",
        "# Save the merged data to a new CSV file\n",
        "df_merged_stage.to_csv(merged_csv, index=False)"
      ],
      "metadata": {
        "id": "2M3emkQ8MOAJ",
        "cellView": "form"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Remove all datasets where SpO2 < 70 or 40 < Pulse < 180 (Meassurement error)\n",
        "\n",
        "# Load the CSV file into a DataFrame\n",
        "df = pd.read_csv(merged_csv)\n",
        "\n",
        "merged_clean_csv = data_prep_dir + \"05_merged_clean.csv\"\n",
        "\n",
        "spo2_threshold = 70\n",
        "pulse_lower_threshold = 40\n",
        "pulse_upper_threshold = 180\n",
        "\n",
        "df = df[df['SpO2'] >= spo2_threshold]\n",
        "df = df[df['Pulse'] >= pulse_lower_threshold]\n",
        "df = df[df['Pulse'] <= pulse_upper_threshold]\n",
        "\n",
        "# Save the filtered DataFrame to a new CSV file\n",
        "df.to_csv(merged_clean_csv, index=False)"
      ],
      "metadata": {
        "id": "rKA0jtgJL-rV",
        "cellView": "form"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Categorize SpO2\n",
        "# @markdown 0-70 = Invalid, 70-80 = Severe Hypoxia, 80-90 = Critical, 90-94 = Decreased, 94-100 = Normal\n",
        "\n",
        "# Load the CSV file into a DataFrame\n",
        "df = pd.read_csv(merged_clean_csv)\n",
        "\n",
        "# Define the name of the output file\n",
        "spo2_categorized_csv = data_prep_dir + \"06_spo2_categorized.csv\"\n",
        "\n",
        "# Define the categorization function\n",
        "def categorize_spo2(value):\n",
        "    if value >= 0 and value < 70:\n",
        "        return 'Invalid'\n",
        "    elif value >= 70 and value < 80:\n",
        "        return 'Severe Hypoxia'\n",
        "    elif value >= 80 and value < 90:\n",
        "        return 'Critical'\n",
        "    elif value >= 90 and value < 94:\n",
        "        return 'Decreased'\n",
        "    elif value >= 94 and value <= 100:\n",
        "        return 'Normal'\n",
        "    else:\n",
        "        return 'Out of Range'  # In case the value is out of the expected range\n",
        "\n",
        "# Apply the categorization function to the relevant column\n",
        "df['SpO2 Category'] = df['SpO2'].apply(categorize_spo2)\n",
        "\n",
        "# Save the DataFrame to a new CSV file (optional)\n",
        "df.to_csv(spo2_categorized_csv, index=False)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "PuQzjFOJIluF"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Categorize Pulse\n",
        "# @markdown Bin size = (max_value - min_value) / number_of_bins\n",
        "number_of_bins = 7 # @param {type:\"integer\"}\n",
        "\n",
        "# Load the CSV file into a DataFrame\n",
        "df = pd.read_csv(spo2_categorized_csv)\n",
        "\n",
        "# Define the name of the output file\n",
        "pulse_categorized_csv = data_prep_dir + \"07_pulse_categorized.csv\"\n",
        "\n",
        "# Find out the smallest and biggest values for pulse\n",
        "min_value = df['Pulse'].min()\n",
        "max_value = df['Pulse'].max()\n",
        "\n",
        "# Calculate the bin size\n",
        "bin_size = (max_value - min_value) / number_of_bins\n",
        "\n",
        "# Create a list of bin edges\n",
        "bin_edges = [min_value + i * bin_size for i in range(number_of_bins + 1)]\n",
        "\n",
        "# Function to assign value to correct bin\n",
        "def categorize_pulse(value):\n",
        "    for i in range(number_of_bins):\n",
        "        if bin_edges[i] <= value < bin_edges[i + 1]:\n",
        "            return f'[{bin_edges[i]:.2f} - {bin_edges[i + 1]:.2f}]'\n",
        "    return f'[{bin_edges[-2]:.2f} - {bin_edges[-1]:.2f}]'  # For the last bin\n",
        "\n",
        "# Apply the categorization function to the relevant column\n",
        "df['Pulse Range'] = df['Pulse'].apply(categorize_pulse)\n",
        "\n",
        "# Save the filtered and categorized DataFrame to a new CSV file\n",
        "df.to_csv(pulse_categorized_csv, index=False)\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "t26iyvLYPKa5"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Set the correct text for sleep phase and remove missing values\n",
        "\n",
        "# Load the CSV file into a DataFrame\n",
        "df = pd.read_csv(pulse_categorized_csv)\n",
        "\n",
        "# Define the name of the output file\n",
        "sleep_stage_text_csv = data_prep_dir + \"08_sleep_stage_text.csv\"\n",
        "\n",
        "# Define the mapping for the \"Sleep Stage\" column\n",
        "sleep_stage_mapping = {\n",
        "    0: 'Wake',\n",
        "    1: 'REM',\n",
        "    2: 'Stage 1',\n",
        "    3: 'Stage 2',\n",
        "    4: 'Stage 3',\n",
        "    5: 'Stage 4',\n",
        "    6: 'Artifact',\n",
        "    7: 'Indeterminate',\n",
        "    8: 'Invalid'\n",
        "}\n",
        "\n",
        "# Apply the mapping to the \"Sleep Stage\" column\n",
        "df['Sleep Stage Text'] = df['Sleep Stage'].map(sleep_stage_mapping)\n",
        "\n",
        "# Save the updated DataFrame to a new CSV file\n",
        "df.to_csv(sleep_stage_text_csv, index=False)"
      ],
      "metadata": {
        "id": "PwjofbhQWtoe",
        "cellView": "form"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Simplify target class\n",
        "\n",
        "# Load the CSV file into a DataFrame\n",
        "df = pd.read_csv(sleep_stage_text_csv)\n",
        "\n",
        "# Define the name of the output file\n",
        "final_csv = data_prep_dir + \"09_final.csv\"\n",
        "\n",
        "def normalize_apnea_column(value):\n",
        "    if str(value).startswith('AP'):\n",
        "        return 'Apnea'\n",
        "    elif str(value).startswith('HYP'):\n",
        "        return 'Hypoapnea'\n",
        "    else:\n",
        "        return 'Nothing'\n",
        "\n",
        "# Apply the normalization function to the target class\n",
        "df['Apnea'] = df['Apnea'].apply(normalize_apnea_column)\n",
        "\n",
        "# Save the filtered, categorized, and normalized DataFrame to a new CSV file\n",
        "df.to_csv(final_csv, index=False)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "N8N5cTvBUwS9"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Copy final csv to results folder\n",
        "\n",
        "# Use shutil.copy to copy the file\n",
        "shutil.copy(final_csv, base_data)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Jcn4nRfll64Q",
        "outputId": "5eddae27-4e54-4f35-980e-6e7c33951d1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'results/subject020/base_data020.csv'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    }
  ]
}